{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Devang_IRExperiment9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "f6ded70b5f8aa8407f55bb1c43ddf4e5d98b0bc63670828ce9dd250cac8c801b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46GA88iKCTnr"
      },
      "source": [
        "Download one of the small web graph dataset from \n",
        "https://snap.stanford.edu/data/web-Stanford.html\n",
        "\n",
        "We have discussed a basic pagerank algorithm in class based on eigenvector computation. Read Chapter 4,5 of the reference and perform page ranking by construction Google pagerank matrix for the downloaded data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UoinbUlAX3s"
      },
      "source": [
        "import networkx as nx\n",
        "import csv\n",
        "f = open('web-Stanford.txt')\n",
        "data=f.readlines()\n",
        "print(f.readlines())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In8Yu_I0BfsH"
      },
      "source": [
        "ndata=data[4:len(data)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei0cZeYaLn1I"
      },
      "source": [
        "ndata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7zyoPBbINhB"
      },
      "source": [
        "\n",
        "G=nx.barabasi_albert_graph(4,2)\n",
        "G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vr1byoqIX50"
      },
      "source": [
        "nx.draw_random(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voZNum8mI-Qr"
      },
      "source": [
        "nx.draw_circular(G,with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5fAZGmeJID2"
      },
      "source": [
        "nx.draw(G, with_labels=True, font_weight='bold')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GDNLj9CKHeR"
      },
      "source": [
        "print(\"Nodes:\",list(G.nodes))\n",
        "print(\"Edges:\",list(G.edges))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC1VzurNQhjX"
      },
      "source": [
        "print(G.is_directed())\n",
        "dg=G.to_directed()\n",
        "nx.draw_circular(dg,with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5uCgTUqKbuO"
      },
      "source": [
        "\n",
        "nG=nx.Graph()\n",
        "nG.add_node(1)\n",
        "nG.add_node(2)\n",
        "nG.add_edge(1,2)\n",
        "print(\"Nodes:\",list(nG.nodes))\n",
        "print(\"Edges:\",list(nG.edges))\n",
        "print(nG.is_directed())\n",
        "nx.draw_circular(nG,with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEMZSJhzSNAw"
      },
      "source": [
        "\n",
        "nG=nx.DiGraph()\n",
        "nG.add_edge(1,2)\n",
        "print(\"Nodes:\",list(nG.nodes))\n",
        "print(\"Edges:\",list(nG.edges))\n",
        "print(nG.is_directed())\n",
        "nx.draw_circular(nG,with_labels=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btxXTd97Lbrw"
      },
      "source": [
        "\n",
        "i=0\n",
        "with open('IR/web-Stanford.txt', 'r') as file:\n",
        "    reader = csv.reader(file,delimiter = '\\t')\n",
        "    for row in reader:\n",
        "        print(row)\n",
        "        i+=1\n",
        "        if i>4:\n",
        "          break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M27kQXO3Jak5"
      },
      "source": [
        "\n",
        "i=0\n",
        "\n",
        "pageG=nx.DiGraph()\n",
        "\n",
        "with open('IR/web-Stanford.txt', 'r') as file:\n",
        "    reader = csv.reader(file,delimiter = '\\t')\n",
        "    for row in reader:\n",
        "      if i>4:\n",
        "        pageG.add_edge(row[0],row[1])\n",
        "      #if i>1000:\n",
        "      #  break\n",
        "      i+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Id1fc6S1T4"
      },
      "source": [
        "pageG.is_directed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAORFydcNEZh"
      },
      "source": [
        "print(\"Nodes:\",len(list(pageG.nodes)))\n",
        "print(\"Edges:\",len(list(pageG.edges)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjvd1cwJNbw6"
      },
      "source": [
        "def pagerank(G, alpha=0.85, personalization=None,\n",
        "\t\t\tmax_iter=100, tol=1.0e-6, nstart=None, weight='weight',\n",
        "\t\t\tdangling=None):\n",
        "\t\n",
        "\tError tolerance used to check convergence in power method solver.\n",
        "\n",
        "\tnstart : dictionary, optional\n",
        "\tStarting value of PageRank iteration for each node.\n",
        "\n",
        "\tweight : key, optional\n",
        "\tEdge data key to use as weight. If None weights are set to 1.\n",
        "\n",
        "\tdangling: dict, optional\n",
        "\tThe outedges to be assigned to any \"dangling\" nodes, i.e., nodes without\n",
        "\tany outedges. The dict key is the node the outedge points to and the dict\n",
        "\tvalue is the weight of that outedge. By default, dangling nodes are given\n",
        "\toutedges according to the personalization vector (uniform if not\n",
        "\tspecified). This must be selected to result in an irreducible transition\n",
        "\tmatrix (see notes under google_matrix). It may be common to have the\n",
        "\tdangling dict to be the same as the personalization dict.\n",
        "\n",
        "\tReturns\n",
        "\t-------\n",
        "\tpagerank : dictionary\n",
        "\tDictionary of nodes with PageRank as value\n",
        "\n",
        "\tNotes\n",
        "\t-----\n",
        "\tThe eigenvector calculation is done by the power iteration method\n",
        "\tand has no guarantee of convergence. The iteration will stop\n",
        "\tafter max_iter iterations or an error tolerance of\n",
        "\tnumber_of_nodes(G)*tol has been reached.\n",
        "\n",
        "\tThe PageRank algorithm was designed for directed graphs but this\n",
        "\talgorithm does not check if the input graph is directed and will\n",
        "\texecute on undirected graphs by converting each edge in the\n",
        "\tdirected graph to two edges.\n",
        "\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tif len(G) == 0:\n",
        "\t\treturn {}\n",
        "\n",
        "\tif not G.is_directed():\n",
        "\t\tD = G.to_directed()\n",
        "\telse:\n",
        "\t\tD = G\n",
        "\n",
        "\t# Create a copy in (right) stochastic form\n",
        "\tW = nx.stochastic_graph(D, weight=weight) #A right-stochastic graph is a weighted digraph in which for each node, the sum of the weights of all the out-edges of that node is 1\n",
        "\tN = W.number_of_nodes()\n",
        "\n",
        "\t# Choose fixed starting vector if not given\n",
        "\tif nstart is None:\n",
        "\t\tx = dict.fromkeys(W, 1.0 / N)\n",
        "\telse:\n",
        "\t\t# Normalized nstart vector\n",
        "\t\ts = float(sum(nstart.values()))\n",
        "\t\tx = dict((k, v / s) for k, v in nstart.items())\n",
        "\n",
        "\tif personalization is None:\n",
        "\n",
        "\t\t# Assign uniform personalization vector if not given\n",
        "\t\tp = dict.fromkeys(W, 1.0 / N)\n",
        "\telse:\n",
        "\t\tmissing = set(G) - set(personalization)\n",
        "\t\tif missing:\n",
        "\t\t\traise NetworkXError('Personalization dictionary '\n",
        "\t\t\t\t\t\t\t\t'must have a value for every node. '\n",
        "\t\t\t\t\t\t\t\t'Missing nodes %s' % missing)\n",
        "\t\ts = float(sum(personalization.values()))\n",
        "\t\tp = dict((k, v / s) for k, v in personalization.items())\n",
        "\n",
        "\tif dangling is None:\n",
        "\n",
        "\t\t# Use personalization vector if dangling vector not specified\n",
        "\t\tdangling_weights = p\n",
        "\telse:\n",
        "\t\tmissing = set(G) - set(dangling)\n",
        "\t\tif missing:\n",
        "\t\t\traise NetworkXError('Dangling node dictionary '\n",
        "\t\t\t\t\t\t\t\t'must have a value for every node. '\n",
        "\t\t\t\t\t\t\t\t'Missing nodes %s' % missing)\n",
        "\t\ts = float(sum(dangling.values()))\n",
        "\t\tdangling_weights = dict((k, v/s) for k, v in dangling.items())\n",
        "\tdangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0]\n",
        "\n",
        "\t# power iteration: make up to max_iter iterations\n",
        "\tfor _ in range(max_iter):\n",
        "\t\txlast = x\n",
        "\t\tx = dict.fromkeys(xlast.keys(), 0)\n",
        "\t\tdanglesum = alpha * sum(xlast[n] for n in dangling_nodes)\n",
        "\t\tfor n in x:\n",
        "\n",
        "\t\t\t# this matrix multiply looks odd because it is\n",
        "\t\t\t# doing a left multiply x^T=xlast^T*W\n",
        "\t\t\tfor nbr in W[n]:\n",
        "\t\t\t\tx[nbr] += alpha * xlast[n] * W[n][nbr][weight]\n",
        "\t\t\t\n",
        "\t\t\tx[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n]\n",
        "\n",
        "\n",
        "\t\t# check convergence, l1 norm\n",
        "\t\terr = sum([abs(x[n] - xlast[n]) for n in x])\n",
        "\t\tif err < N*tol:\n",
        "\t\t\treturn x\n",
        "\traise NetworkXError('pagerank: power iteration failed to converge '\n",
        "\t\t\t\t\t\t'in %d iterations.' % max_iter)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl3AP_FmOANv"
      },
      "source": [
        "pr=nx.pagerank(pageG,0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg38RWd5OJzW"
      },
      "source": [
        "import operator\n",
        "sorted_d = dict( sorted(pr.items(), key=operator.itemgetter(1),reverse=True))\n",
        "sorted_d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha3krvJsFh6d"
      },
      "source": [
        "import numpy as np\n",
        "np.sum(list(sorted_d.values()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}